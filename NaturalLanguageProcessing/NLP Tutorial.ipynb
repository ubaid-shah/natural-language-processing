{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1bdb5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default string:  ₹50 \n",
      " Type of string <class 'str'> \n",
      "\n",
      "Encoded to UTF-8:  b'\\xe2\\x82\\xb950' \n",
      " Type of string <class 'bytes'> \n",
      "\n",
      "Decoded from UTF-8:  ₹50 \n",
      " Type of string <class 'str'> \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create a string\n",
    "amount = u\"₹50\"\n",
    "print('Default string: ', amount, '\\n', 'Type of string', type(amount), '\\n')\n",
    "\n",
    "# encode to UTF-8 byte format\n",
    "amount_encoded = amount.encode('utf-8')\n",
    "print('Encoded to UTF-8: ', amount_encoded, '\\n', 'Type of string', type(amount_encoded), '\\n')\n",
    "\n",
    "\n",
    "# sometime later in another computer...\n",
    "# decode from UTF-8 byte format\n",
    "amount_decoded = amount_encoded.decode('utf-8')\n",
    "print('Decoded from UTF-8: ', amount_decoded, '\\n', 'Type of string', type(amount_decoded), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1ba2843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the regular expression module\n",
    "import re\n",
    "\n",
    "# input string on which to test regex pattern\n",
    "string = 'The roots of education are bitter, but the fruit is sweet.'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0deb96aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regex pattern to check if 'education' is present in a input string or not.\n",
    "pattern = re.search(\"education?\",string).group() # write regex to extract 'education'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6926a3c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'education'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "addcc538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(13, 22), match='education'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check whether pattern is present in string or not\n",
    "result = re.search(pattern, string)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3afd5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# evaluate result - don't change the following piece of code, it is used to evaluate your regex\n",
    "if result != None:\n",
    "    print(True)\n",
    "else:\n",
    "    print(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e79ccffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(13, 22), match='education'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02cc9a0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'education'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "559e30a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.start()    # to find the index of start of pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c04adae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store the end of the match using result.end()\n",
    "result.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e51d5df8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to find the number of characters that has been matched from pattern\n",
    "result.end()-result.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a7f595d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=[\"The tree stands tall.\",\"There are a lot of trees in the forest.\",\n",
    "      'The boy is heading for the school.',\"It's really hot outside!\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8f5eade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba1e69a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern=\"tree?\"\n",
    "list1 = []\n",
    "for sentences in text:\n",
    "    list1.append(re.search(pattern,sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "633ed38c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<re.Match object; span=(4, 8), match='tree'>,\n",
       " <re.Match object; span=(19, 23), match='tree'>,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e300d0b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(0, 2), match='xy'>\n"
     ]
    }
   ],
   "source": [
    "pattern1='xyz*'\n",
    "result1=re.search(pattern1,'xyyyz')\n",
    "print(result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e2920a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern ='10+' # write your pattern here\n",
    "\n",
    "# check whether pattern is present in string or not\n",
    "result = re.search(pattern,'1000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e346e528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 4), match='1000'>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b1911644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(0, 13), match='awesomeeeeeee'>\n"
     ]
    }
   ],
   "source": [
    "pattern ='awesome{3,}' # write your regex pattern here\n",
    "\n",
    "# check whether pattern is present in string or not\n",
    "result = re.search(pattern, \"awesomeeeeeee\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b5fb05d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "94d1a87b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(0, 13), match='2323233787878'>\n"
     ]
    }
   ],
   "source": [
    "pattern = '(23)+[0-9]*(78)+' # write your regex here\n",
    "\n",
    "# check whether pattern is present in string or not\n",
    "result = re.search(pattern, \"2323233787878\")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4b18b0d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(0, 11), match='Cricketball'> \n",
      " <re.Match object; span=(0, 11), match='CricketBall'>\n"
     ]
    }
   ],
   "source": [
    "# Write a regular expression that matches the following strings: \n",
    "# Basketball \n",
    "# Baseball \n",
    "# Volleyball \n",
    "# Softball \n",
    "# Football\n",
    "\n",
    "\n",
    "# regex pattern\n",
    "pattern = '(Basket|Base|Volley|Soft|Foot|Cricket)(B|b)all' # write your egex here\n",
    "\n",
    "# check whether pattern is present in string or not\n",
    "result = re.search(pattern, \"Cricketball\")\n",
    "result1 = re.search(pattern, \"CricketBall\")\n",
    "\n",
    "\n",
    "print(result,\"\\n\",result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "25e1eb9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(0, 2), match='4*'>\n"
     ]
    }
   ],
   "source": [
    "pattern = '[0-9]*[a-z]*\\*' # write your regex here\n",
    "\n",
    "# check whether pattern is present in string or not\n",
    "result = re.search(pattern, \"4*5*6=120\")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6d40af7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(1, 2), match='*'>\n"
     ]
    }
   ],
   "source": [
    "pattern = '\\*' # write your regex here\n",
    "\n",
    "# check whether pattern is present in string or not\n",
    "result = re.search(pattern, \"4*5*6=120\")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "566cd93e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(0, 3), match='4a*'>\n"
     ]
    }
   ],
   "source": [
    "pattern = '[0-9]*[a-z]*\\*' # write your regex here\n",
    "\n",
    "# check whether pattern is present in string or not\n",
    "result = re.search(pattern, \"4a*5b*6c=120\")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a50c3e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result:  <re.Match object; span=(0, 1), match='A'>\n",
      "result1:  None\n"
     ]
    }
   ],
   "source": [
    "'''Anchors\n",
    "Description\n",
    "Write a pattern that matches all the dictionary words that start with ‘A’\n",
    "\n",
    "Positive matches (should match all of these):\n",
    "Avenger\n",
    "Acute\n",
    "Altruism\n",
    "\n",
    "Negative match (shouldn’t match any of these):\n",
    "Bribe\n",
    "10\n",
    "Zenith '''\n",
    "\n",
    "\n",
    "# regex pattern\n",
    "pattern = '^a' # write your regex here\n",
    "\n",
    "# check whether pattern is present in string or not\n",
    "result = re.search(pattern, \"Avengers\", re.I)  # re.I ignores the case of the string and the pattern\n",
    "result1 = re.search(pattern, \"Bribe\", re.I)\n",
    "print(\"result: \" ,result)\n",
    "print(\"result1: \",result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "654bb0c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result:  <re.Match object; span=(3, 6), match='ing'>\n",
      "result1:  None\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Write a pattern which matches a word that ends with ‘ing’.\n",
    "Words such as ‘playing’, ‘growing’, ‘raining’, etc. should match while words that don’t have ‘ing’ at the end shouldn’t match.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# regex pattern\n",
    "pattern = '(ing)$' # write your regex here\n",
    "\n",
    "# check whether pattern is present in string or not\n",
    "result = re.search(pattern,\"string\")  \n",
    "result1 = re.search(pattern,\"strig\")  \n",
    "\n",
    "print(\"result: \" ,result)\n",
    "print(\"result1: \",result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86b42a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result:  None\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Write a regular expression that matches any string that starts with one or more ‘1’s, \n",
    "followed by three or more ‘0’s, \n",
    "followed by any number of ones (zero or more), \n",
    "followed by ‘0’s (from one to seven), \n",
    "and then ends with either two or three ‘1’s.\n",
    "\"\"\"\n",
    "\n",
    "pattern = '^1+0{3,}1*0{1,7}1{2,3}$' # write your regex here\n",
    "\n",
    "# check whether pattern is present in string or not\n",
    "result = re.search(pattern, \"100100000100001\")\n",
    "\n",
    "print(\"result: \" ,result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c219e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(0, 14), match='Balasubrahmany'>\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Write a regular expression to match first names (consider only first names, i.e. there are no spaces in a name) \n",
    "that have length between three and fifteen characters.\n",
    "\n",
    "Sample positive match:\n",
    "Amandeep\n",
    "Krishna\n",
    "\n",
    "Sample negative match:\n",
    "Balasubrahmanyam\n",
    "'''\n",
    "string=\"Balasubrahmanyam\"\n",
    "pattern = '.{3,14}' # write your regex here\n",
    "\n",
    "# check whether pattern is present in string or not\n",
    "result = re.search(pattern, string)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1124611e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(0, 10), match='irfann2590'>\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Meta-sequences\n",
    "Description\n",
    "Write a regular expression with the help of meta-sequences that matches usernames of the users of a database. \n",
    "\n",
    "The username starts with alphabets of length one to ten characters long and then followed by a number of length 4.\n",
    "\n",
    "Sample positive matches:\n",
    "sam2340 \n",
    "irfann2590 \n",
    "\n",
    "Sample negative matches:\n",
    "8730 \n",
    "bobby9073834 \n",
    "sameer728 \n",
    "radhagopalaswamy7890\n",
    "'''\n",
    "\n",
    "\n",
    "# regex pattern\n",
    "pattern = '^[a-z]{1,10}[\\d]{4}$'\n",
    "\n",
    "# check whether pattern is present in string or not\n",
    "result = re.search(pattern, \"irfann2590\", re.I)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30767a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'irfann2590'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ea04abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "<re.Match object; span=(0, 103), match='<html> <head> <title> My amazing webpage </title>>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "string= '<html> <head> <title> My amazing webpage </title> </head> <body> Welcome to my webpage! </body> </html>' \n",
    "\n",
    "\n",
    "\n",
    "# regex pattern\n",
    "pattern = '<.*>'\n",
    "\n",
    "# check whether pattern is present in string or not\n",
    "result = re.search(pattern, string, re.M)  # re.M enables tha tpettern to be searched in multiple lines\n",
    "\n",
    "# evaluate result - don't change the following piece of code, it is used to evaluate your regex\n",
    "if (result != None) and (len(result.group()) > 6):\n",
    "    print(True)\n",
    "else:\n",
    "    print(False)\n",
    "    \n",
    "print (result)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f38adc54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "<re.Match object; span=(0, 6), match='<html>'>\n"
     ]
    }
   ],
   "source": [
    "string= '<html> <head> <title> My amazing webpage </title> </head> <body> Welcome to my webpage! </body> </html>' \n",
    "\n",
    "\n",
    "\n",
    "# regex pattern\n",
    "pattern = '<.*?>'\n",
    "\n",
    "# check whether pattern is present in string or not\n",
    "result = re.search(pattern, string, re.M)  # re.M enables tha tpettern to be searched in multiple lines\n",
    "\n",
    "# evaluate result - don't change the following piece of code, it is used to evaluate your regex\n",
    "if (result != None) and (len(result.group()) > 6):\n",
    "    print(True)\n",
    "else:\n",
    "    print(False)\n",
    "    \n",
    "print (result)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c8daa8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "<re.Match object; span=(0, 1), match='b'>\n",
      "<re.Match object; span=(0, 4), match='bulb'>\n"
     ]
    }
   ],
   "source": [
    "print(re.match(\"b+\", \"absurd\"))\n",
    "print(re.match(\"b+\", \"britain\"))\n",
    "print(re.match(\"b+.b*..\", \"bulb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deddb3c3",
   "metadata": {},
   "source": [
    "**re.match()** returns a non-empty match only if the match is present at the very beginning of the string. The pattern is present in the string right at the start."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19396d4",
   "metadata": {},
   "source": [
    "The **re.sub()** function is used to substitute a part of your string using a regex pattern. It is often the case when you want to replace a substring of your string where the substring has a particular pattern that can be matched by the regex engine and then it is replaced by the **re.sub()** command. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6c31184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My address is XXB, Baker Street'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = \"\\d\"\n",
    "replacement = \"X\"\n",
    "string = \"My address is 13B, Baker Street\"\n",
    "\n",
    "re.sub(pattern, replacement, string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3e9908b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pink is very good colour.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string=\"Pink is very good clour.\"\n",
    "re.sub(\"clour\", \"colour\", string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0edad1f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'####'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You are given the following string: \n",
    "\n",
    "# “You can reach us at 07400029954 or 02261562153 ”\n",
    " \n",
    "# Substitute all the 11-digit phone numbers present in the above string with “####”. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# regex pattern\n",
    "pattern = '[0-9]{11}' # write a regex that detects 11-digit number\n",
    "\n",
    "# replacement string\n",
    "replacement = '####' # write the replacement string\n",
    "\n",
    "# check whether pattern is present in string or not\n",
    "result = re.sub(pattern,replacement,\"12345678901\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d85d5043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1234567890'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You are given the following string: \n",
    "\n",
    "# “You can reach us at 07400029954 or 02261562153 ”\n",
    " \n",
    "# Substitute all the 11-digit phone numbers present in the above string with “####”. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# regex pattern\n",
    "pattern = '\\d{11}' # write a regex that detects 11-digit number\n",
    "\n",
    "# replacement string\n",
    "replacement = '####' # write the replacement string\n",
    "\n",
    "# check whether pattern is present in string or not\n",
    "result = re.sub(pattern,replacement,\"1234567890\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2cee87af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "$uilding careers of tomorrow\n"
     ]
    }
   ],
   "source": [
    "# Write a regular expression such that it replaces the first letter of any given string with ‘$’. \n",
    "\n",
    "# For example, the string ‘Building careers of tomorrow’ should be replaced by “$uilding careers of tomorrow”.\n",
    "\n",
    "string= 'Building careers of tomorrow'\n",
    "pattern = '^.' # write a regex that detects the first character of a string\n",
    "\n",
    "# replacement string\n",
    "replacement = '$' # write the replacement string\n",
    "\n",
    "# check whether pattern is present in string or not\n",
    "result = re.sub(pattern,replacement,string)  # pass the parameters to the sub function\n",
    "\n",
    "# evaluate result - don't change the following piece of code, it is used to evaluate your regex\n",
    "print(result[0] == '$')\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7a314fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START - 0END - 62\n"
     ]
    }
   ],
   "source": [
    "## Example usage of finditer(). Find all occurrences of word Festival in given sentence\n",
    "\n",
    "text = 'Do not compare apples with oranges. Compare apples with apples'\n",
    "pattern = '(.){5,}'\n",
    "for match in re.finditer(pattern, text):\n",
    "    print('START -', match.start(), end=\"\")\n",
    "    print('END -', match.end())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9b616daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<re.Match object; span=(7, 14), match='compare'>,\n",
       " <re.Match object; span=(15, 21), match='apples'>,\n",
       " <re.Match object; span=(27, 34), match='oranges'>,\n",
       " <re.Match object; span=(36, 43), match='Compare'>,\n",
       " <re.Match object; span=(44, 50), match='apples'>,\n",
       " <re.Match object; span=(56, 62), match='apples'>]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import ast, sys\n",
    "string = 'Do not compare apples with oranges. Compare apples with apples'\n",
    "\n",
    "# regex pattern\n",
    "pattern = \"\\w+\"\n",
    "\n",
    "# store results in the list 'result'\n",
    "result = []\n",
    "\n",
    "# iterate over the matches\n",
    "for match in re.finditer(pattern,string): # replace the ___ with the 'finditer' function to extract 'pattern' from the 'string'\n",
    "    if len(match.group()) >= 5:\n",
    "        result.append(match)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "# evaluate result - don't change the following piece of code, it is used to evaluate your regex\n",
    "print(len(result))\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bd686d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Playing', 'raining']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write a regular expression to extract all the words that have the suffix ‘ing’ using the re.findall() function. \n",
    "# Store the matches in the variable ‘results’ and print its length.\n",
    "\n",
    "Sample= \"Playing outdoor games when its raining outside is always fun!\"\n",
    "\n",
    "\n",
    "pattern = '\\w+ing' # write regex to extract words ending with 'ing'\n",
    "\n",
    "# store results in the list 'result'\n",
    "result =re.findall(pattern,Sample) # extract words having the required pattern, using the findall function\n",
    "\n",
    "# evaluate result - don't change the following piece of code, it is used to evaluate your regex\n",
    "print(len(result))\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2a043754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['games', 'when', 'outside ']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sample= \"Playing outdoor games when its raining outside is always fun!\"\n",
    "pattern = '\\w+e.'\n",
    "result =re.findall(pattern,Sample)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e6225222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fun!']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sample= \"Playing outdoor games when its raining outside is always fun!\"\n",
    "pattern = '\\w+!'\n",
    "result =re.findall(pattern,Sample)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e37df61c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fun!']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sample= \"Playing outdoor games when its raining outside is always fun!\"\n",
    "pattern = re.compile('\\w+!')\n",
    "result =pattern.findall(Sample)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fd941953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'18-05-2018'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You have a string which contains a data in the format DD-MM-YYYY. Write a regular expression to extract \n",
    "# the date from the string.\n",
    "\n",
    "# Sample input: \"Today’s date is 18-05-2018.\"\n",
    "\n",
    "# Sample output: 18-05-2018\n",
    "\n",
    "string=\"Today’s date is 18-05-2018.\"\n",
    "\n",
    "pattern = '(\\d{2})-(\\d{2})-(\\d{4})' # write regex to extract date in DD-MM-YYYY format\n",
    "\n",
    "# store result\n",
    "result = re.search(pattern,string).group() \n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63652837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gmail.com\n"
     ]
    }
   ],
   "source": [
    "# Write a regular expression to extract the domain name from an email address. \n",
    "# The format of the email is simple - the part before the ‘@’ symbol contains alphabets, numbers and underscores. \n",
    "# The part after the ‘@’ symbol contains only alphabets followed by a dot followed by ‘com’ \n",
    " \n",
    "# Sample input: \n",
    "# user_name_123@gmail.com \n",
    " \n",
    "# Expected output: \n",
    "# gmail.com\n",
    "\n",
    "\n",
    "string=\"user_name_123@gmail.com\"\n",
    "# regex pattern\n",
    "pattern = '(@)(\\w+\\.com)' # write regex to extract email and use groups to extract domain name ofthe mail\n",
    "\n",
    "# store result\n",
    "result = re.search(pattern, string)\n",
    "\n",
    "# extract domain using group command\n",
    "if result != None:\n",
    "    domain = result.group(2) # use group to extract the domain from result\n",
    "else:\n",
    "    domain = \"NA\"\n",
    "\n",
    "# evaluate result - don't change the following piece of code, it is used to evaluate your regex\n",
    "print(domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f79a401f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['image001.jpg', 'image002.jpg', 'image005.jpg', 'wallpaper.jpg', 'flower.jpg', 'earth.jpg', 'monkey.jpg', 'image002.png']\n"
     ]
    }
   ],
   "source": [
    "# items contains all the files and folders of current directory\n",
    "items = ['photos', 'documents', 'videos', 'image001.jpg','image002.jpg','image005.jpg', 'wallpaper.jpg',\n",
    "         'flower.jpg', 'earth.jpg', 'monkey.jpg', 'image002.png']\n",
    "\n",
    "# create an empty list to store resultant files\n",
    "images = []\n",
    "\n",
    "# regex pattern to extract files that end with '.jpg'\n",
    "pattern = \".*\\.(jpg|png)$\"\n",
    "\n",
    "for item in items:\n",
    "    if re.search(pattern, item):\n",
    "        images.append(item)\n",
    "\n",
    "# print result\n",
    "print(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98f95c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['image001.jpg', 'image002.jpg', 'image005.jpg']\n"
     ]
    }
   ],
   "source": [
    "# items contains all the files and folders of current directory\n",
    "items = ['photos', 'documents', 'videos', 'image001.jpg','image002.jpg','image005.jpg', 'wallpaper.jpg',\n",
    "         'flower.jpg', 'earth.jpg', 'monkey.jpg', 'image002.png']\n",
    "\n",
    "# create an empty list to store resultant files\n",
    "images = []\n",
    "\n",
    "# regex pattern to extract files that start with 'image' and end with '.jpg'\n",
    "pattern = \"image.*\\.jpg$\"\n",
    "\n",
    "for item in items:\n",
    "    if re.search(pattern, item):\n",
    "        images.append(item)\n",
    "\n",
    "# print result\n",
    "print(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c8ce6ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ubaid Shah\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:1013: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.gutenberg.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1206\n"
     ]
    }
   ],
   "source": [
    "# You learnt how to extract and plot word frequencies from a list of words. In this exercise,\n",
    "# you need to extract the third most frequent word of a book (the book is provided) and print it's frequency.\n",
    "\n",
    "\n",
    "import requests\n",
    "from nltk import FreqDist\n",
    "\n",
    "# load the ebook\n",
    "url = \"https://www.gutenberg.org/files/16/16-0.txt\"\n",
    "peter_pan = requests.get(url,verify=False)\n",
    "\n",
    "# break the book into different words using the split() method\n",
    "peter_pan_words = peter_pan.text.split() # write your code here\n",
    "\n",
    "# build frequency distribution using NLTK's FreqDist() function\n",
    "word_frequency = FreqDist(peter_pan_words) # write your code here\n",
    "\n",
    "# extract the frequency of third most frequent word\n",
    "freq = word_frequency.most_common(3)[2][1]\n",
    "\n",
    "# print the third most frequent word - don't change the following code, it is used to evaluate the code\n",
    "print(freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2a625d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'the': 2318, 'and': 1388, 'to': 1206, 'a': 956, 'of': 919, 'was': 899, 'he': 866, 'in': 681, 'that': 565, 'had': 497, ...})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5138f9d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 2318), ('and', 1388), ('to', 1206)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq1 = word_frequency.most_common(3)\n",
    "freq1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a232c8df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('to', 1206)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq2 = word_frequency.most_common(3)[2]\n",
    "freq2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05cbdd2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1206"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq3 = word_frequency.most_common(3)[2][1]\n",
    "freq3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee459024",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ubaid Shah\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:1013: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.gutenberg.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "253\n"
     ]
    }
   ],
   "source": [
    "# In this exercise, you'll remove stop words in a given corpus of text of a book. \n",
    "# Then, you'll print the frequency of the most frequent word.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import requests\n",
    "from nltk import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# load the ebook\n",
    "url = \"https://www.gutenberg.org/files/16/16-0.txt\"\n",
    "peter_pan = requests.get(url,verify=False).text\n",
    "\n",
    "# break the book into different words using the split() method\n",
    "peter_pan_words = peter_pan.split()\n",
    "\n",
    "# build frequency distribution using NLTK's FreqDist() function\n",
    "word_frequency = FreqDist(peter_pan_words)\n",
    "\n",
    "# extract nltk stop word list\n",
    "stopwords = stopwords.words('english')\n",
    "\n",
    "# remove 'stopwords' from 'peter_pan_words'\n",
    "no_stops = [word for word in peter_pan_words if word not in stopwords] # write code here\n",
    "\n",
    "# create word frequency of no_stops\n",
    "word_frequency = FreqDist(no_stops) # write code here\n",
    "\n",
    "# extract the most frequent word and its frequency\n",
    "frequency = word_frequency.most_common(1)[0][1]\n",
    "\n",
    "# print the third most frequent word - don't change the following code, it is used to evaluate the code\n",
    "print(frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d782da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "url1=\"https://cdn.upgrad.com/UpGrad/temp/bab3e784-e601-4911-9000-f1fbc994a62d/SMSSpamCollection.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c68ed900",
   "metadata": {},
   "outputs": [],
   "source": [
    "url2= \"https://cdn.upgrad.com/UpGrad/temp/a4964625-11c7-4043-adc5-23c0160b2ac1/SMSSpamCollection.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca9e7238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('bagsofwords.txt', <http.client.HTTPMessage at 0x2e59f5f5af0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request    \n",
    "urllib.request.urlretrieve(url2, \"bagsofwords.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ea7ad1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Ubaid\n",
      "[nltk_data]     Shah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d3d8421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import ast, sys\n",
    "sentence = \"I Love Pasta!\"\n",
    "\n",
    "# tokenise sentence into words\n",
    "words = word_tokenize(sentence)# write your code here\n",
    "\n",
    "# print length - don't change the following piece of code\n",
    "print(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a388769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "# Write a piece of code that breaks a given sentence into words and stores them in a list. \n",
    "# Then remove the stop words from this list and then print the length of the list. Again, use the NLTK tokeniser to do this.\n",
    "\n",
    "# Sample input: \n",
    "# “Education is the most powerful weapon that you can use to change the world” \n",
    "\n",
    "# Expected output: \n",
    "# 6\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import ast, sys\n",
    "sentence = 'Education is the most powerful weapon that you can use to change the world'\n",
    "\n",
    "# change sentence to lowercase\n",
    "sentence = sentence.lower() # write code here\n",
    "\n",
    "# tokenise sentence into words\n",
    "words = word_tokenize(sentence) # write code here\n",
    "\n",
    "# extract nltk stop word list\n",
    "stopwords = stopwords.words('english') # write code here\n",
    "\n",
    "# remove stop words\n",
    "no_stops = [word for word in words if word not in stopwords] # write code here\n",
    "\n",
    "# print length - don't change the following piece of code\n",
    "print(len(no_stops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e80eddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# Write a Python code using the NLTK library that breaks a given piece of text containing \n",
    "# multiple sentences into different sentences. Finally print the total number of sentences in the text.\n",
    "\n",
    "# Sample input: \n",
    "# Develop a passion for your learning. If you do, you’ll never cease to grow.\n",
    "\n",
    "# Expected output:\n",
    "\n",
    "# 2 \n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "sentence = 'Develop a passion for your learning. If you do, you’ll never cease to grow.'\n",
    "\n",
    "# change sentence to lowercase\n",
    "sentence = sentence.lower() # write code here\n",
    "\n",
    "# tokenise sentence into words\n",
    "sentence = sent_tokenize(sentence) # write code here\n",
    "\n",
    "\n",
    "# print length - don't change the following piece of code\n",
    "print(len(sentence))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5ed47f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['@upgrad', '@iiitb']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Description\n",
    "# Use NLTK’s regex tokeniser to extract all the mentions from a given tweet and \n",
    "# then print the total number of mentions. A mention comprises of a ‘@’ symbol followed \n",
    "# by a username containing either alphabets, numbers or underscores.\n",
    "\n",
    "# Sample tweet:\n",
    "# So excited to be a part of machine learning and artificial intelligence program made by @upgrad and @iiitb\n",
    "\n",
    "# Expected output:\n",
    "# 2 (because there are two mentions - ‘@upgrad’ and ‘@iiitb’ )\n",
    "\n",
    "\n",
    "\n",
    "from nltk.tokenize import regexp_tokenize \n",
    "from nltk.corpus import stopwords\n",
    "import ast, sys\n",
    "text = 'So excited to be a part of machine learning and artificial intelligence program made by @upgrad and @iiitb'\n",
    "\n",
    "# change text to lowercase\n",
    "text = text.lower() # write code here\n",
    "\n",
    "# pattern to extract mentions\n",
    "pattern = \"@\\w+\" # write regex pattern here\n",
    "\n",
    "# extract mentions by using regex tokeniser\n",
    "mentions = regexp_tokenize(text,pattern) # write code here\n",
    "\n",
    "# print length - don't change the following piece of code\n",
    "print(len(mentions))\n",
    "mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcf8a074",
   "metadata": {},
   "outputs": [],
   "source": [
    "url3= \"https://www.msn.com/en-in/entertainment/other/lata-mangeshkar-s-death-breaks-bollywood-akshay-kumar-kangana-ranaut-sonu-sood-and-ocean-of-celebs-mourn-demise/ar-AATw17k?ocid=msedgntp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "351daad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('msn_news.txt', <http.client.HTTPMessage at 0x2e59f5f5be0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urllib.request.urlretrieve(url3, \"msn_news.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c990fcac",
   "metadata": {},
   "source": [
    "# Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f174f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all necessary libraries\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "pd.set_option('max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2ed095d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  \\\n",
       "0   ham   \n",
       "1   ham   \n",
       "2  spam   \n",
       "3   ham   \n",
       "4   ham   \n",
       "\n",
       "                                                                                               message  \n",
       "0  Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...  \n",
       "1                                                                        Ok lar... Joking wif u oni...  \n",
       "2  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...  \n",
       "3                                                    U dun say so early hor... U c already then say...  \n",
       "4                                        Nah I don't think he goes to usf, he lives around here though  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "spam = pd.read_csv(\"bagsofwords.txt\", sep = \"\\t\", names=[\"label\", \"message\"])\n",
    "spam.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b12e6114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label  \\\n",
      "0    ham   \n",
      "1    ham   \n",
      "2   spam   \n",
      "3    ham   \n",
      "4    ham   \n",
      "..   ...   \n",
      "95  spam   \n",
      "96   ham   \n",
      "97   ham   \n",
      "98   ham   \n",
      "99   ham   \n",
      "\n",
      "                                                                                                message  \n",
      "0   Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...  \n",
      "1                                                                         Ok lar... Joking wif u oni...  \n",
      "2   Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...  \n",
      "3                                                     U dun say so early hor... U c already then say...  \n",
      "4                                         Nah I don't think he goes to usf, he lives around here though  \n",
      "..                                                                                                  ...  \n",
      "95  Your free ringtone is waiting to be collected. Simply text the password \"MIX\" to 85069 to verify...  \n",
      "96                                                                    Watching telugu movie..wat abt u?  \n",
      "97                                                  i see. When we finish we have loads of loans to pay  \n",
      "98  Hi. Wk been ok - on hols now! Yes on for a bit of a run. Forgot that i have hairdressers appoint...  \n",
      "99                                                                      I see a cup of coffee animation  \n",
      "\n",
      "[100 rows x 2 columns] (100, 2)\n"
     ]
    }
   ],
   "source": [
    "spam = spam.iloc[0:100,:]\n",
    "print(spam,spam.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6f97a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...\n",
      "1                                                                           Ok lar... Joking wif u oni...\n",
      "2     Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...\n",
      "3                                                       U dun say so early hor... U c already then say...\n",
      "4                                           Nah I don't think he goes to usf, he lives around here though\n",
      "                                                     ...                                                 \n",
      "95    Your free ringtone is waiting to be collected. Simply text the password \"MIX\" to 85069 to verify...\n",
      "96                                                                      Watching telugu movie..wat abt u?\n",
      "97                                                    i see. When we finish we have loads of loans to pay\n",
      "98    Hi. Wk been ok - on hols now! Yes on for a bit of a run. Forgot that i have hairdressers appoint...\n",
      "99                                                                        I see a cup of coffee animation\n",
      "Name: message, Length: 100, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# extract the messages from the dataframe\n",
    "messages = spam.message\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4944a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...', 'Ok lar... Joking wif u oni...', \"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\", 'U dun say so early hor... U c already then say...', \"Nah I don't think he goes to usf, he lives around here though\", \"FreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, £1.50 to rcv\", 'Even my brother is not like to speak with me. They treat me like aids patent.', \"As per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertune for all Callers. Press *9 to copy your friends Callertune\", 'WINNER!! As a valued network customer you have been selected to receivea £900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.', 'Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on 08002986030', \"I'm gonna be home soon and i don't want to talk about this stuff anymore tonight, k? I've cried enough today.\", 'SIX chances to win CASH! From 100 to 20,000 pounds txt> CSH11 and send to 87575. Cost 150p/day, 6days, 16+ TsandCs apply Reply HL 4 info', 'URGENT! You have won a 1 week FREE membership in our £100,000 Prize Jackpot! Txt the word: CLAIM to No: 81010 T&C www.dbuk.net LCCLTD POBOX 4403LDNW1A7RW18', \"I've been searching for the right words to thank you for this breather. I promise i wont take your help for granted and will fulfil my promise. You have been wonderful and a blessing at all times.\", 'I HAVE A DATE ON SUNDAY WITH WILL!!', 'XXXMobileMovieClub: To use your credit, click the WAP link in the next txt message or click here>> http://wap. xxxmobilemovieclub.com?n=QJKGIGHJJGCBL', \"Oh k...i'm watching here:)\", 'Eh u remember how 2 spell his name... Yes i did. He v naughty make until i v wet.', 'Fine if that\\x92s the way u feel. That\\x92s the way its gota b', 'England v Macedonia - dont miss the goals/team news. Txt ur national team to 87077 eg ENGLAND to 87077 Try:WALES, SCOTLAND 4txt/ú1.20 POBOXox36504W45WQ 16+', 'Is that seriously how you spell his name?', 'I‘m going to try for 2 months ha ha only joking', 'So ü pay first lar... Then when is da stock comin...', 'Aft i finish my lunch then i go str down lor. Ard 3 smth lor. U finish ur lunch already?', 'Ffffffffff. Alright no way I can meet up with you sooner?', \"Just forced myself to eat a slice. I'm really not hungry tho. This sucks. Mark is getting worried. He knows I'm sick when I turn down pizza. Lol\", 'Lol your always so convincing.', \"Did you catch the bus ? Are you frying an egg ? Did you make a tea? Are you eating your mom's left over dinner ? Do you feel my Love ?\", \"I'm back &amp; we're packing the car now, I'll let you know if there's room\", 'Ahhh. Work. I vaguely remember that! What does it feel like? Lol', \"Wait that's still not all that clear, were you not sure about me being sarcastic or that that's why x doesn't want to live with us\", \"Yeah he got in at 2 and was v apologetic. n had fallen out and she was actin like spoilt child and he got caught up in that. Till 2! But we won't go there! Not doing too badly cheers. You? \", 'K tell me anything about you.', 'For fear of fainting with the of all that housework you just did? Quick have a cuppa', 'Thanks for your subscription to Ringtone UK your mobile will be charged £5/month Please confirm by replying YES or NO. If you reply NO you will not be charged', 'Yup... Ok i go home look at the timings then i msg ü again... Xuhui going to learn on 2nd may too but her lesson is at 8am', \"Oops, I'll let you know when my roommate's done\", 'I see the letter B on my car', 'Anything lor... U decide...', \"Hello! How's you and how did saturday go? I was just texting to see if you'd decided to do anything tomo. Not that i'm trying to invite myself or anything!\", 'Pls go ahead with watts. I just wanted to be sure. Do have a great weekend. Abiola', 'Did I forget to tell you ? I want you , I need you, I crave you ... But most of all ... I love you my sweet Arabian steed ... Mmmmmm ... Yummy', '07732584351 - Rodger Burns - MSG = We tried to call you re your reply to our sms for a free nokia mobile + free camcorder. Please call now 08000930705 for delivery tomorrow', 'WHO ARE YOU SEEING?', 'Great! I hope you like your man well endowed. I am  &lt;#&gt;  inches...', 'No calls..messages..missed calls', \"Didn't you get hep b immunisation in nigeria.\", 'Fair enough, anything going on?', \"Yeah hopefully, if tyler can't do it I could maybe ask around a bit\", \"U don't know how stubborn I am. I didn't even want to go to the hospital. I kept telling Mark I'm not a weak sucker. Hospitals are for weak suckers.\", 'What you thinked about me. First time you saw me in class.', 'A gram usually runs like  &lt;#&gt; , a half eighth is smarter though and gets you almost a whole second gram for  &lt;#&gt;', \"K fyi x has a ride early tomorrow morning but he's crashing at our place tonight\", 'Wow. I never realized that you were so embarassed by your accomodations. I thought you liked it, since i was doing the best i could and you always seemed so happy about \"the cave\". I\\'m sorry I didn\\'t and don\\'t have more to give. I\\'m sorry i offered. I\\'m sorry your room was so embarassing.', 'SMS. ac Sptv: The New Jersey Devils and the Detroit Red Wings play Ice Hockey. Correct or Incorrect? End? Reply END SPTV', 'Do you know what Mallika Sherawat did yesterday? Find out now @  &lt;URL&gt;', 'Congrats! 1 year special cinema pass for 2 is yours. call 09061209465 now! C Suprman V, Matrix3, StarWars3, etc all 4 FREE! bx420-ip4-5we. 150pm. Dont miss out! ', \"Sorry, I'll call later in meeting.\", 'Tell where you reached', 'Yes..gauti and sehwag out of odi series.', \"Your gonna have to pick up a $1 burger for yourself on your way home. I can't even move. Pain is killing me.\", 'Ha ha ha good joke. Girls are situation seekers.', 'Its a part of checking IQ', 'Sorry my roommates took forever, it ok if I come by now?', 'Ok lar i double check wif da hair dresser already he said wun cut v short. He said will cut until i look nice.', 'As a valued customer, I am pleased to advise you that following recent review of your Mob No. you are awarded with a £1500 Bonus Prize, call 09066364589', 'Today is \"song dedicated day..\" Which song will u dedicate for me? Send this to all ur valuable frnds but first rply me...', 'Urgent UR awarded a complimentary trip to EuroDisinc Trav, Aco&Entry41 Or £1000. To claim txt DIS to 87121 18+6*£1.50(moreFrmMob. ShrAcomOrSglSuplt)10, LS1 3AJ', 'Did you hear about the new \"Divorce Barbie\"? It comes with all of Ken\\'s stuff!', 'I plane to give on this month end.', 'Wah lucky man... Then can save money... Hee...', 'Finished class where are you.', 'HI BABE IM AT HOME NOW WANNA DO SOMETHING? XX', 'K..k:)where are you?how did you performed?', 'U can call me now...', 'I am waiting machan. Call me once you free.', 'Thats cool. i am a gentleman and will treat you with dignity and respect.', 'I like you peoples very much:) but am very shy pa.', 'Does not operate after  &lt;#&gt;  or what', \"Its not the same here. Still looking for a job. How much do Ta's earn there.\", \"Sorry, I'll call later\", 'K. Did you call me just now ah? ', 'Ok i am on the way to home hi hi', 'You will be in the place of that man', 'Yup next stop.', \"I call you later, don't have network. If urgnt, sms me.\", \"For real when u getting on yo? I only need 2 more tickets and one more jacket and I'm done. I already used all my multis.\", \"Yes I started to send requests to make it but pain came back so I'm back in bed. Double coins at the factory too. I gotta cash in all my nitros.\", \"I'm really not up to it still tonight babe\", 'Ela kano.,il download, come wen ur free..', 'Yeah do! Don‘t stand to close tho- you‘ll catch something!', \"Sorry to be a pain. Is it ok if we meet another night? I spent late afternoon in casualty and that means i haven't done any of y stuff42moro and that includes all my time sheets and that. Sorry. \", 'Smile in Pleasure Smile in Pain Smile when trouble pours like Rain Smile when sum1 Hurts U Smile becoz SOMEONE still Loves to see u Smiling!!', 'Please call our customer service representative on 0800 169 6031 between 10am-9pm as you have WON a guaranteed £1000 cash or £5000 prize!', 'Havent planning to buy later. I check already lido only got 530 show in e afternoon. U finish work already?', 'Your free ringtone is waiting to be collected. Simply text the password \"MIX\" to 85069 to verify. Get Usher and Britney. FML, PO Box 5249, MK17 92H. 450Ppw 16', 'Watching telugu movie..wat abt u?', 'i see. When we finish we have loads of loans to pay', 'Hi. Wk been ok - on hols now! Yes on for a bit of a run. Forgot that i have hairdressers appointment at four so need to get home n shower beforehand. Does that cause prob for u?\"', 'I see a cup of coffee animation']\n"
     ]
    }
   ],
   "source": [
    "# convert messages into list\n",
    "messages = [message for message in messages]\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ac3f3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(document):\n",
    "    'changes document to lower case and removes stopwords'\n",
    "\n",
    "    # change sentence to lower case\n",
    "    document = document.lower()\n",
    "\n",
    "    # tokenize into words\n",
    "    words = word_tokenize(document)\n",
    "\n",
    "    # remove stop words\n",
    "    words = [word for word in words if word not in stopwords.words(\"english\")]\n",
    "\n",
    "    # join words to make sentence\n",
    "    document = \" \".join(words)\n",
    "    \n",
    "    return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b210987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['go jurong point , crazy .. available bugis n great world la e buffet ... cine got amore wat ...', 'ok lar ... joking wif u oni ...', \"free entry 2 wkly comp win fa cup final tkts 21st may 2005. text fa 87121 receive entry question ( std txt rate ) & c 's apply 08452810075over18 's\", 'u dun say early hor ... u c already say ...', \"nah n't think goes usf , lives around though\", \"freemsg hey darling 's 3 week 's word back ! 'd like fun still ? tb ok ! xxx std chgs send , £1.50 rcv\", 'even brother like speak . treat like aids patent .', \"per request 'melle melle ( oru minnaminunginte nurungu vettam ) ' set callertune callers . press * 9 copy friends callertune\", 'winner ! ! valued network customer selected receivea £900 prize reward ! claim call 09061701461. claim code kl341 . valid 12 hours .', 'mobile 11 months ? u r entitled update latest colour mobiles camera free ! call mobile update co free 08002986030', \"'m gon na home soon n't want talk stuff anymore tonight , k ? 've cried enough today .\", 'six chances win cash ! 100 20,000 pounds txt > csh11 send 87575. cost 150p/day , 6days , 16+ tsandcs apply reply hl 4 info', 'urgent ! 1 week free membership £100,000 prize jackpot ! txt word : claim : 81010 & c www.dbuk.net lccltd pobox 4403ldnw1a7rw18', \"'ve searching right words thank breather . promise wont take help granted fulfil promise . wonderful blessing times .\", 'date sunday ! !', 'xxxmobilemovieclub : use credit , click wap link next txt message click > > http : //wap . xxxmobilemovieclub.com ? n=qjkgighjjgcbl', \"oh k ... 'm watching : )\", 'eh u remember 2 spell name ... yes . v naughty make v wet .', 'fine that\\x92s way u feel . that\\x92s way gota b', 'england v macedonia - dont miss goals/team news . txt ur national team 87077 eg england 87077 try : wales , scotland 4txt/ú1.20 poboxox36504w45wq 16+', 'seriously spell name ?', '‘ going try 2 months ha ha joking', 'ü pay first lar ... da stock comin ...', 'aft finish lunch go str lor . ard 3 smth lor . u finish ur lunch already ?', 'ffffffffff . alright way meet sooner ?', \"forced eat slice . 'm really hungry tho . sucks . mark getting worried . knows 'm sick turn pizza . lol\", 'lol always convincing .', \"catch bus ? frying egg ? make tea ? eating mom 's left dinner ? feel love ?\", \"'m back & amp ; 're packing car , 'll let know 's room\", 'ahhh . work . vaguely remember ! feel like ? lol', \"wait 's still clear , sure sarcastic 's x n't want live us\", \"yeah got 2 v apologetic . n fallen actin like spoilt child got caught . till 2 ! wo n't go ! badly cheers . ?\", 'k tell anything .', 'fear fainting housework ? quick cuppa', 'thanks subscription ringtone uk mobile charged £5/month please confirm replying yes . reply charged', 'yup ... ok go home look timings msg ü ... xuhui going learn 2nd may lesson 8am', \"oops , 'll let know roommate 's done\", 'see letter b car', 'anything lor ... u decide ...', \"hello ! 's saturday go ? texting see 'd decided anything tomo . 'm trying invite anything !\", 'pls go ahead watts . wanted sure . great weekend . abiola', 'forget tell ? want , need , crave ... ... love sweet arabian steed ... mmmmmm ... yummy', '07732584351 - rodger burns - msg = tried call reply sms free nokia mobile + free camcorder . please call 08000930705 delivery tomorrow', 'seeing ?', 'great ! hope like man well endowed . & lt ; # & gt ; inches ...', 'calls .. messages .. missed calls', \"n't get hep b immunisation nigeria .\", 'fair enough , anything going ?', \"yeah hopefully , tyler ca n't could maybe ask around bit\", \"u n't know stubborn . n't even want go hospital . kept telling mark 'm weak sucker . hospitals weak suckers .\", 'thinked . first time saw class .', 'gram usually runs like & lt ; # & gt ; , half eighth smarter though gets almost whole second gram & lt ; # & gt ;', \"k fyi x ride early tomorrow morning 's crashing place tonight\", \"wow . never realized embarassed accomodations . thought liked , since best could always seemed happy `` cave '' . 'm sorry n't n't give . 'm sorry offered . 'm sorry room embarassing .\", 'sms . ac sptv : new jersey devils detroit red wings play ice hockey . correct incorrect ? end ? reply end sptv', 'know mallika sherawat yesterday ? find @ & lt ; url & gt ;', 'congrats ! 1 year special cinema pass 2 . call 09061209465 ! c suprman v , matrix3 , starwars3 , etc 4 free ! bx420-ip4-5we . 150pm . dont miss !', \"sorry , 'll call later meeting .\", 'tell reached', 'yes .. gauti sehwag odi series .', \"gon na pick $ 1 burger way home . ca n't even move . pain killing .\", 'ha ha ha good joke . girls situation seekers .', 'part checking iq', 'sorry roommates took forever , ok come ?', 'ok lar double check wif da hair dresser already said wun cut v short . said cut look nice .', 'valued customer , pleased advise following recent review mob . awarded £1500 bonus prize , call 09066364589', \"today `` song dedicated day .. '' song u dedicate ? send ur valuable frnds first rply ...\", 'urgent ur awarded complimentary trip eurodisinc trav , aco & entry41 £1000 . claim txt dis 87121 18+6 * £1.50 ( morefrmmob . shracomorsglsuplt ) 10 , ls1 3aj', \"hear new `` divorce barbie '' ? comes ken 's stuff !\", 'plane give month end .', 'wah lucky man ... save money ... hee ...', 'finished class .', 'hi babe im home wan na something ? xx', 'k .. k : ) ? performed ?', 'u call ...', 'waiting machan . call free .', 'thats cool . gentleman treat dignity respect .', 'like peoples much : ) shy pa .', 'operate & lt ; # & gt ;', \". still looking job . much ta 's earn .\", \"sorry , 'll call later\", 'k. call ah ?', 'ok way home hi hi', 'place man', 'yup next stop .', \"call later , n't network . urgnt , sms .\", \"real u getting yo ? need 2 tickets one jacket 'm done . already used multis .\", \"yes started send requests make pain came back 'm back bed . double coins factory . got ta cash nitros .\", \"'m really still tonight babe\", 'ela kano. , il download , come wen ur free ..', 'yeah ! ‘ stand close tho- ‘ catch something !', \"sorry pain . ok meet another night ? spent late afternoon casualty means n't done stuff42moro includes time sheets . sorry .\", 'smile pleasure smile pain smile trouble pours like rain smile sum1 hurts u smile becoz someone still loves see u smiling ! !', 'please call customer service representative 0800 169 6031 10am-9pm guaranteed £1000 cash £5000 prize !', 'havent planning buy later . check already lido got 530 show e afternoon . u finish work already ?', \"free ringtone waiting collected . simply text password `` mix '' 85069 verify . get usher britney . fml , po box 5249 , mk17 92h . 450ppw 16\", 'watching telugu movie .. wat abt u ?', 'see . finish loads loans pay', \"hi . wk ok - hols ! yes bit run . forgot hairdressers appointment four need get home n shower beforehand . cause prob u ? ''\", 'see cup coffee animation']\n"
     ]
    }
   ],
   "source": [
    "# preprocess messages using the preprocess function\n",
    "messages = [preprocess(message) for message in messages]\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0a5a36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bag of words model\n",
    "vectorizer = CountVectorizer()\n",
    "bow_model = vectorizer.fit_transform(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "563cbdc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 237)\t1\n",
      "  (0, 294)\t1\n",
      "  (0, 419)\t1\n",
      "  (0, 150)\t1\n",
      "  (0, 75)\t1\n",
      "  (0, 93)\t1\n",
      "  (0, 247)\t1\n",
      "  (0, 623)\t1\n",
      "  (0, 302)\t1\n",
      "  (0, 92)\t1\n",
      "  (0, 121)\t1\n",
      "  (0, 243)\t1\n",
      "  (0, 62)\t1\n",
      "  (0, 600)\t1\n",
      "  (1, 389)\t1\n",
      "  (1, 303)\t1\n",
      "  (1, 293)\t1\n",
      "  (1, 611)\t1\n",
      "  (1, 391)\t1\n",
      "  (2, 222)\t1\n",
      "  (2, 196)\t2\n",
      "  (2, 616)\t1\n",
      "  (2, 138)\t1\n",
      "  (2, 612)\t1\n",
      "  (2, 201)\t2\n",
      "  :\t:\n",
      "  (97, 469)\t1\n",
      "  (97, 320)\t1\n",
      "  (97, 321)\t1\n",
      "  (98, 389)\t1\n",
      "  (98, 266)\t1\n",
      "  (98, 634)\t1\n",
      "  (98, 373)\t1\n",
      "  (98, 232)\t1\n",
      "  (98, 85)\t1\n",
      "  (98, 262)\t1\n",
      "  (98, 615)\t1\n",
      "  (98, 265)\t1\n",
      "  (98, 458)\t1\n",
      "  (98, 220)\t1\n",
      "  (98, 252)\t1\n",
      "  (98, 70)\t1\n",
      "  (98, 221)\t1\n",
      "  (98, 484)\t1\n",
      "  (98, 83)\t1\n",
      "  (98, 112)\t1\n",
      "  (98, 424)\t1\n",
      "  (99, 154)\t1\n",
      "  (99, 469)\t1\n",
      "  (99, 130)\t1\n",
      "  (99, 64)\t1\n"
     ]
    }
   ],
   "source": [
    "print(bow_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4fe98f40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>07732584351</th>\n",
       "      <th>0800</th>\n",
       "      <th>08000930705</th>\n",
       "      <th>08002986030</th>\n",
       "      <th>08452810075over18</th>\n",
       "      <th>09061209465</th>\n",
       "      <th>09061701461</th>\n",
       "      <th>09066364589</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>xxx</th>\n",
       "      <th>xxxmobilemovieclub</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>yes</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yo</th>\n",
       "      <th>yummy</th>\n",
       "      <th>yup</th>\n",
       "      <th>ú1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 640 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    000  07732584351  0800  08000930705  08002986030  08452810075over18  \\\n",
       "0     0            0     0            0            0                  0   \n",
       "1     0            0     0            0            0                  0   \n",
       "2     0            0     0            0            0                  1   \n",
       "3     0            0     0            0            0                  0   \n",
       "4     0            0     0            0            0                  0   \n",
       "..  ...          ...   ...          ...          ...                ...   \n",
       "95    0            0     0            0            0                  0   \n",
       "96    0            0     0            0            0                  0   \n",
       "97    0            0     0            0            0                  0   \n",
       "98    0            0     0            0            0                  0   \n",
       "99    0            0     0            0            0                  0   \n",
       "\n",
       "    09061209465  09061701461  09066364589  10  ...  xxx  xxxmobilemovieclub  \\\n",
       "0             0            0            0   0  ...    0                   0   \n",
       "1             0            0            0   0  ...    0                   0   \n",
       "2             0            0            0   0  ...    0                   0   \n",
       "3             0            0            0   0  ...    0                   0   \n",
       "4             0            0            0   0  ...    0                   0   \n",
       "..          ...          ...          ...  ..  ...  ...                 ...   \n",
       "95            0            0            0   0  ...    0                   0   \n",
       "96            0            0            0   0  ...    0                   0   \n",
       "97            0            0            0   0  ...    0                   0   \n",
       "98            0            0            0   0  ...    0                   0   \n",
       "99            0            0            0   0  ...    0                   0   \n",
       "\n",
       "    yeah  year  yes  yesterday  yo  yummy  yup  ú1  \n",
       "0      0     0    0          0   0      0    0   0  \n",
       "1      0     0    0          0   0      0    0   0  \n",
       "2      0     0    0          0   0      0    0   0  \n",
       "3      0     0    0          0   0      0    0   0  \n",
       "4      0     0    0          0   0      0    0   0  \n",
       "..   ...   ...  ...        ...  ..    ...  ...  ..  \n",
       "95     0     0    0          0   0      0    0   0  \n",
       "96     0     0    0          0   0      0    0   0  \n",
       "97     0     0    0          0   0      0    0   0  \n",
       "98     0     0    1          0   0      0    0   0  \n",
       "99     0     0    0          0   0      0    0   0  \n",
       "\n",
       "[100 rows x 640 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at the dataframe\n",
    "pd.DataFrame(bow_model.toarray(), columns = vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3db770fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "size=vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f71be7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['000', '07732584351', '0800', '08000930705', '08002986030', '08452810075over18', '09061209465', '09061701461', '09066364589', '10', '100', '1000', '10am', '11', '12', '1500', '150p', '150pm', '16', '169', '18', '20', '2005', '21st', '2nd', '3aj', '4403ldnw1a7rw18', '450ppw', '4txt', '50', '5000', '5249', '530', '5we', '6031', '6days', '81010', '85069', '87077', '87121', '87575', '8am', '900', '92h', '9pm', 'abiola', 'abt', 'ac', 'accomodations', 'aco', 'actin', 'advise', 'aft', 'afternoon', 'ah', 'ahead', 'ahhh', 'aids', 'almost', 'already', 'alright', 'always', 'amore', 'amp', 'animation', 'another', 'anymore', 'anything', 'apologetic', 'apply', 'appointment', 'arabian', 'ard', 'around', 'ask', 'available', 'awarded', 'babe', 'back', 'badly', 'barbie', 'becoz', 'bed', 'beforehand', 'best', 'bit', 'blessing', 'bonus', 'box', 'breather', 'britney', 'brother', 'buffet', 'bugis', 'burger', 'burns', 'bus', 'buy', 'bx420', 'ca', 'call', 'callers', 'callertune', 'calls', 'camcorder', 'came', 'camera', 'car', 'cash', 'casualty', 'catch', 'caught', 'cause', 'cave', 'chances', 'charged', 'check', 'checking', 'cheers', 'chgs', 'child', 'cine', 'cinema', 'claim', 'class', 'clear', 'click', 'close', 'co', 'code', 'coffee', 'coins', 'collected', 'colour', 'com', 'come', 'comes', 'comin', 'comp', 'complimentary', 'confirm', 'congrats', 'convincing', 'cool', 'copy', 'correct', 'cost', 'could', 'crashing', 'crave', 'crazy', 'credit', 'cried', 'csh11', 'cup', 'cuppa', 'customer', 'cut', 'da', 'darling', 'date', 'day', 'dbuk', 'decide', 'decided', 'dedicate', 'dedicated', 'delivery', 'detroit', 'devils', 'dignity', 'dinner', 'dis', 'divorce', 'done', 'dont', 'double', 'download', 'dresser', 'dun', 'early', 'earn', 'eat', 'eating', 'eg', 'egg', 'eh', 'eighth', 'ela', 'embarassed', 'embarassing', 'end', 'endowed', 'england', 'enough', 'entitled', 'entry', 'entry41', 'etc', 'eurodisinc', 'even', 'fa', 'factory', 'fainting', 'fair', 'fallen', 'fear', 'feel', 'ffffffffff', 'final', 'find', 'fine', 'finish', 'finished', 'first', 'fml', 'following', 'forced', 'forever', 'forget', 'forgot', 'four', 'free', 'freemsg', 'friends', 'frnds', 'frying', 'fulfil', 'fun', 'fyi', 'gauti', 'gentleman', 'get', 'gets', 'getting', 'girls', 'give', 'go', 'goals', 'goes', 'going', 'gon', 'good', 'got', 'gota', 'gram', 'granted', 'great', 'gt', 'guaranteed', 'ha', 'hair', 'hairdressers', 'half', 'happy', 'havent', 'hear', 'hee', 'hello', 'help', 'hep', 'hey', 'hi', 'hl', 'hockey', 'hols', 'home', 'hope', 'hopefully', 'hor', 'hospital', 'hospitals', 'hours', 'housework', 'http', 'hungry', 'hurts', 'ice', 'il', 'im', 'immunisation', 'inches', 'includes', 'incorrect', 'info', 'invite', 'ip4', 'iq', 'jacket', 'jackpot', 'jersey', 'job', 'joke', 'joking', 'jurong', 'kano', 'ken', 'kept', 'killing', 'kl341', 'know', 'knows', 'la', 'lar', 'late', 'later', 'latest', 'lccltd', 'learn', 'left', 'lesson', 'let', 'letter', 'lido', 'like', 'liked', 'link', 'live', 'lives', 'll', 'loads', 'loans', 'lol', 'look', 'looking', 'lor', 'love', 'loves', 'ls1', 'lt', 'lucky', 'lunch', 'macedonia', 'machan', 'make', 'mallika', 'man', 'mark', 'matrix3', 'may', 'maybe', 'means', 'meet', 'meeting', 'melle', 'membership', 'message', 'messages', 'minnaminunginte', 'miss', 'missed', 'mix', 'mk17', 'mmmmmm', 'mob', 'mobile', 'mobiles', 'mom', 'money', 'month', 'months', 'morefrmmob', 'morning', 'move', 'movie', 'msg', 'much', 'multis', 'na', 'nah', 'name', 'national', 'naughty', 'need', 'net', 'network', 'never', 'new', 'news', 'next', 'nice', 'nigeria', 'night', 'nitros', 'nokia', 'nurungu', 'odi', 'offered', 'oh', 'ok', 'one', 'oni', 'oops', 'operate', 'oru', 'pa', 'packing', 'pain', 'part', 'pass', 'password', 'patent', 'pay', 'peoples', 'per', 'performed', 'pick', 'pizza', 'place', 'plane', 'planning', 'play', 'please', 'pleased', 'pleasure', 'pls', 'po', 'pobox', 'poboxox36504w45wq', 'point', 'pounds', 'pours', 'press', 'prize', 'prob', 'promise', 'qjkgighjjgcbl', 'question', 'quick', 'rain', 'rate', 'rcv', 're', 'reached', 'real', 'realized', 'really', 'receive', 'receivea', 'recent', 'red', 'remember', 'reply', 'replying', 'representative', 'request', 'requests', 'respect', 'review', 'reward', 'ride', 'right', 'ringtone', 'rodger', 'room', 'roommate', 'roommates', 'rply', 'run', 'runs', 'said', 'sarcastic', 'saturday', 'save', 'saw', 'say', 'scotland', 'searching', 'second', 'see', 'seeing', 'seekers', 'seemed', 'sehwag', 'selected', 'send', 'series', 'seriously', 'service', 'set', 'sheets', 'sherawat', 'short', 'show', 'shower', 'shracomorsglsuplt', 'shy', 'sick', 'simply', 'since', 'situation', 'six', 'slice', 'smarter', 'smile', 'smiling', 'sms', 'smth', 'someone', 'something', 'song', 'soon', 'sooner', 'sorry', 'speak', 'special', 'spell', 'spent', 'spoilt', 'sptv', 'stand', 'started', 'starwars3', 'std', 'steed', 'still', 'stock', 'stop', 'str', 'stubborn', 'stuff', 'stuff42moro', 'subscription', 'sucker', 'suckers', 'sucks', 'sum1', 'sunday', 'suprman', 'sure', 'sweet', 'ta', 'take', 'talk', 'tb', 'tea', 'team', 'tell', 'telling', 'telugu', 'text', 'texting', 'thank', 'thanks', 'that', 'thats', 'think', 'thinked', 'tho', 'though', 'thought', 'tickets', 'till', 'time', 'times', 'timings', 'tkts', 'today', 'tomo', 'tomorrow', 'tonight', 'took', 'trav', 'treat', 'tried', 'trip', 'trouble', 'try', 'trying', 'tsandcs', 'turn', 'txt', 'tyler', 'uk', 'update', 'ur', 'urgent', 'urgnt', 'url', 'us', 'use', 'used', 'usf', 'usher', 'usually', 'vaguely', 'valid', 'valuable', 'valued', 've', 'verify', 'vettam', 'wah', 'wait', 'waiting', 'wales', 'wan', 'want', 'wanted', 'wap', 'wat', 'watching', 'watts', 'way', 'weak', 'week', 'weekend', 'well', 'wen', 'wet', 'whole', 'wif', 'win', 'wings', 'winner', 'wk', 'wkly', 'wo', 'wonderful', 'wont', 'word', 'words', 'work', 'world', 'worried', 'wow', 'wun', 'www', 'xuhui', 'xx', 'xxx', 'xxxmobilemovieclub', 'yeah', 'year', 'yes', 'yesterday', 'yo', 'yummy', 'yup', 'ú1']\n"
     ]
    }
   ],
   "source": [
    "print(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9493ff25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "640"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9303d828",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d794f66",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ac84b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Play\n",
      "Playing\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import ast, sys\n",
    "word = \"Playing\"\n",
    "\n",
    "# create function to chop off the suffixes 'ing' and 'ed'\n",
    "def stemmer(word):\n",
    "    if re.search('(ing|ed)$',word):\n",
    "        word= re.sub('(ing|ed)$',\"\",word) # write your code here   \n",
    "    return word\n",
    "\n",
    "# stem word -- don't change the following code, it is used to evaluate your code\n",
    "print(stemmer(word))\n",
    "\n",
    "print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87701ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "employi\n"
     ]
    }
   ],
   "source": [
    "print(stemmer(\"employied\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34c80a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "garden\n"
     ]
    }
   ],
   "source": [
    "# Use Porter stemmer to stem a given word\n",
    "\n",
    "# Sample input:\n",
    "# Gardening\n",
    "\n",
    "# Expected output:\n",
    "# Garden\n",
    "\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import ast, sys\n",
    "word = \"Gardening\"\n",
    "\n",
    "# instantiate porter stemmer\n",
    "stemmer = PorterStemmer() # write code here\n",
    "\n",
    "# stem word\n",
    "stemmed = stemmer.stem(word) # write your code here\n",
    "\n",
    "# print stemmed word -- don't change the following code, it is used to evaluate your code\n",
    "print(stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4e97ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "come\n"
     ]
    }
   ],
   "source": [
    "# Stem a given word using Snowball stemmer.\n",
    "\n",
    "# Sample input:\n",
    "# coming\n",
    "\n",
    "# Expected output:\n",
    "# come\n",
    "\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import ast, sys\n",
    "word = \"coming\"\n",
    "\n",
    "# instantiate porter stemmer\n",
    "stemmer = SnowballStemmer(\"english\") # write code here\n",
    "\n",
    "# stem word\n",
    "stemmed = stemmer.stem(word) # write code here\n",
    "\n",
    "# print stemmed word -- don't change the following code, it is used to evaluate your code\n",
    "print(stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "292ba145",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Ubaid\n",
      "[nltk_data]     Shah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "344030b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "school\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "import ast, sys\n",
    "word = \"schooling\"\n",
    "\n",
    "# instantiate wordnet lemmatizer\n",
    "lemmatizer = WordNetLemmatizer() # write code here\n",
    "\n",
    "# lemmatize word\n",
    "lemmatized = lemmatizer.lemmatize(word,pos=\"v\") # write code here. Pass the parameter -> pos='v' to the lemmatize function to lemmatize verbs correctly.\n",
    "\n",
    "# print lemmatized word -- don't change the following code, it is used to evaluate your code\n",
    "print(lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c201ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# consider the following set of documents\n",
    "documents = [\"The coach lumbered on again, with heavier wreaths of mist closing round it as it began the descent.\",\n",
    "             \"The guard soon replaced his blunderbuss in his arm-chest, and, having looked to the rest of its contents, and having looked to the supplementary pistols that he wore in his belt, looked to a smaller chest beneath his seat, in which there were a few smith's tools, a couple of torches, and a tinder-box.\",\n",
    "            \"For he was furnished with that completeness that if the coach-lamps had been blown and stormed out, which did occasionally happen, he had only to shut himself up inside, keep the flint and steel sparks well off the straw, and get a light with tolerable safety and ease (if he were lucky) in five minutes.\",\n",
    "            \"Jerry, left alone in the mist and darkness, dismounted meanwhile, not only to ease his spent horse, but to wipe the mud from his face, and shake the wet out of his hat-brim, which might be capable of holding about half a gallon.\",\n",
    "            \"After standing with the bridle over his heavily-splashed arm, until the wheels of the mail were no longer within hearing and the night was quite still again, he turned to walk down the hill.\"]\n",
    "\n",
    "\n",
    "# preprocess document\n",
    "def preprocess(document):\n",
    "    'changes document to lower case, removes stopwords and stems words'\n",
    "\n",
    "    # change sentence to lower case\n",
    "    document = document.lower()\n",
    "\n",
    "    # tokenize into words\n",
    "    words = word_tokenize(document)\n",
    "\n",
    "    # remove stop words\n",
    "    words = [word for word in words if word not in stopwords.words(\"english\")]\n",
    "    \n",
    "    # stem\n",
    "    stemmer = PorterStemmer()\n",
    "    words = [stemmer.stem(word) for word in words]\n",
    "    \n",
    "    # join words to make sentence\n",
    "    document = \" \".join(words)\n",
    "    \n",
    "    return document\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "664317ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['coach lumber , heavier wreath mist close round began descent .', \"guard soon replac blunderbuss arm-chest , , look rest content , look supplementari pistol wore belt , look smaller chest beneath seat , smith 's tool , coupl torch , tinder-box .\", 'furnish complet coach-lamp blown storm , occa happen , shut insid , keep flint steel spark well straw , get light toler safeti ea ( lucki ) five minut .', 'jerri , left alon mist dark , dismount meanwhil , ea spent hor , wipe mud face , shake wet hat-brim , might capabl hold half gallon .', 'stand bridl heavily-splash arm , wheel mail longer within hear night quit still , turn walk hill .']\n"
     ]
    }
   ],
   "source": [
    "# preprocess documents using the preprocess function and store the documents again in a list\n",
    "documents = [preprocess(document) for document in documents] # write code here\n",
    "print(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "764dd101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 18)\t0.34706676322953556\n",
      "  (0, 2)\t0.34706676322953556\n",
      "  (0, 59)\t0.34706676322953556\n",
      "  (0, 12)\t0.34706676322953556\n",
      "  (0, 51)\t0.28001127926354535\n",
      "  (0, 88)\t0.34706676322953556\n",
      "  (0, 32)\t0.34706676322953556\n",
      "  (0, 46)\t0.34706676322953556\n",
      "  (0, 13)\t0.28001127926354535\n",
      "  (1, 7)\t0.17500574860015003\n",
      "  (1, 76)\t0.17500574860015003\n",
      "  (1, 79)\t0.17500574860015003\n",
      "  (1, 16)\t0.17500574860015003\n",
      "  (1, 78)\t0.17500574860015003\n",
      "  (1, 65)\t0.17500574860015003\n",
      "  (1, 61)\t0.17500574860015003\n",
      "  (1, 4)\t0.17500574860015003\n",
      "  (1, 64)\t0.17500574860015003\n",
      "  (1, 3)\t0.17500574860015003\n",
      "  (1, 87)\t0.17500574860015003\n",
      "  (1, 55)\t0.17500574860015003\n",
      "  (1, 75)\t0.17500574860015003\n",
      "  (1, 15)\t0.17500574860015003\n",
      "  (1, 58)\t0.17500574860015003\n",
      "  (1, 44)\t0.5250172458004501\n",
      "  :\t:\n",
      "  (3, 68)\t0.21666637672403882\n",
      "  (3, 48)\t0.21666637672403882\n",
      "  (3, 19)\t0.21666637672403882\n",
      "  (3, 17)\t0.21666637672403882\n",
      "  (3, 0)\t0.21666637672403882\n",
      "  (3, 41)\t0.21666637672403882\n",
      "  (3, 38)\t0.21666637672403882\n",
      "  (3, 20)\t0.1748050684985107\n",
      "  (3, 51)\t0.1748050684985107\n",
      "  (4, 34)\t0.2527726716084208\n",
      "  (4, 81)\t0.2527726716084208\n",
      "  (4, 80)\t0.2527726716084208\n",
      "  (4, 72)\t0.2527726716084208\n",
      "  (4, 56)\t0.2527726716084208\n",
      "  (4, 53)\t0.2527726716084208\n",
      "  (4, 31)\t0.2527726716084208\n",
      "  (4, 86)\t0.2527726716084208\n",
      "  (4, 43)\t0.2527726716084208\n",
      "  (4, 47)\t0.2527726716084208\n",
      "  (4, 84)\t0.2527726716084208\n",
      "  (4, 69)\t0.2527726716084208\n",
      "  (4, 33)\t0.2527726716084208\n",
      "  (4, 8)\t0.2527726716084208\n",
      "  (4, 70)\t0.2527726716084208\n",
      "  (4, 1)\t0.20393539986751064\n"
     ]
    }
   ],
   "source": [
    "# create tf-idf matrix\n",
    "## write code here ##\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_model = vectorizer.fit_transform(documents)\n",
    "print(tfidf_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45da7b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract score\n",
    "score =tfidf_model[2,14] # replace -1 with the score of 'belt' in document two. You can manually write the value by looking at the tf_idf model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e600dc67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2072\n"
     ]
    }
   ],
   "source": [
    "# print the score -- don't change the following piece od code, it's used to evaluate your code\n",
    "print(round(score, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5966015d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       alon       arm     began      belt   beneath    blown  blunderbuss  \\\n",
      "0  0.000000  0.000000  0.347067  0.000000  0.000000  0.00000     0.000000   \n",
      "1  0.000000  0.141194  0.000000  0.175006  0.175006  0.00000     0.175006   \n",
      "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.20716     0.000000   \n",
      "3  0.216666  0.000000  0.000000  0.000000  0.000000  0.00000     0.000000   \n",
      "4  0.000000  0.203935  0.000000  0.000000  0.000000  0.00000     0.000000   \n",
      "\n",
      "        box     bridl      brim  ...     torch      turn      walk     well  \\\n",
      "0  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.00000   \n",
      "1  0.175006  0.000000  0.000000  ...  0.175006  0.000000  0.000000  0.00000   \n",
      "2  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.20716   \n",
      "3  0.000000  0.000000  0.216666  ...  0.000000  0.000000  0.000000  0.00000   \n",
      "4  0.000000  0.252773  0.000000  ...  0.000000  0.252773  0.252773  0.00000   \n",
      "\n",
      "        wet     wheel      wipe    within      wore    wreath  \n",
      "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.347067  \n",
      "1  0.000000  0.000000  0.000000  0.000000  0.175006  0.000000  \n",
      "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
      "3  0.216666  0.000000  0.216666  0.000000  0.000000  0.000000  \n",
      "4  0.000000  0.252773  0.000000  0.252773  0.000000  0.000000  \n",
      "\n",
      "[5 rows x 89 columns]\n"
     ]
    }
   ],
   "source": [
    "tf_idf = pd.DataFrame(tfidf_model.toarray(), columns = vectorizer.get_feature_names())\n",
    "\n",
    "# check score of 'belt' in document two\n",
    "print(tf_idf)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800aa943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract score\n",
    "score = 0.175006\n",
    "\n",
    "# print the score of the term ''\n",
    "print(round(score, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0bf8e00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alon</th>\n",
       "      <th>arm</th>\n",
       "      <th>began</th>\n",
       "      <th>belt</th>\n",
       "      <th>beneath</th>\n",
       "      <th>blown</th>\n",
       "      <th>blunderbuss</th>\n",
       "      <th>box</th>\n",
       "      <th>bridl</th>\n",
       "      <th>brim</th>\n",
       "      <th>...</th>\n",
       "      <th>torch</th>\n",
       "      <th>turn</th>\n",
       "      <th>walk</th>\n",
       "      <th>well</th>\n",
       "      <th>wet</th>\n",
       "      <th>wheel</th>\n",
       "      <th>wipe</th>\n",
       "      <th>within</th>\n",
       "      <th>wore</th>\n",
       "      <th>wreath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.347067</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.347067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.141194</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.175006</td>\n",
       "      <td>0.175006</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.175006</td>\n",
       "      <td>0.175006</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.175006</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.175006</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.20716</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.20716</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.216666</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.216666</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.216666</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.216666</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.203935</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.252773</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.252773</td>\n",
       "      <td>0.252773</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.252773</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.252773</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       alon       arm     began      belt   beneath    blown  blunderbuss  \\\n",
       "0  0.000000  0.000000  0.347067  0.000000  0.000000  0.00000     0.000000   \n",
       "1  0.000000  0.141194  0.000000  0.175006  0.175006  0.00000     0.175006   \n",
       "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.20716     0.000000   \n",
       "3  0.216666  0.000000  0.000000  0.000000  0.000000  0.00000     0.000000   \n",
       "4  0.000000  0.203935  0.000000  0.000000  0.000000  0.00000     0.000000   \n",
       "\n",
       "        box     bridl      brim  ...     torch      turn      walk     well  \\\n",
       "0  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.00000   \n",
       "1  0.175006  0.000000  0.000000  ...  0.175006  0.000000  0.000000  0.00000   \n",
       "2  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.20716   \n",
       "3  0.000000  0.000000  0.216666  ...  0.000000  0.000000  0.000000  0.00000   \n",
       "4  0.000000  0.252773  0.000000  ...  0.000000  0.252773  0.252773  0.00000   \n",
       "\n",
       "        wet     wheel      wipe    within      wore    wreath  \n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.347067  \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.175006  0.000000  \n",
       "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "3  0.216666  0.000000  0.216666  0.000000  0.000000  0.000000  \n",
       "4  0.000000  0.252773  0.000000  0.252773  0.000000  0.000000  \n",
       "\n",
       "[5 rows x 89 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7bb644c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.175"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round((tf_idf[\"belt\"].iloc[1]),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f430e00b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.175"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round((tf_idf.belt.loc[1]),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1dcf99c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
